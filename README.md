Laff-O-Tron: Laugh Prediction for TED Talks
By Andrew Acosta, as a Master's Thesis for Cal Poly SLO Computer Science

Laff-O-Tron is an A.I. that tries to predict when laughter will occur in a TED Talk. For more information, please see the thesis paper at: FILL IN WITH ADDRESS.

Please see stack.txt for what you need to download to run this. Please update it if anything is missing.

============================================Files================================================
main.py: The main file. Explanation for how it works is at the bottom.

-------------------------------------------Laff-O-Tron--------------------------------------
Classifiers.py: The file for all things related to the classifiers. Functions here handle creating, running, and assesing the classifiers.

DataCreator.py: This file handles functions for taking in the parsed TED websites and breaking them up into chunks with their feature dictionaries. Stopword removal, case collapsing, and things altering the chunk is done. Sends altered chunks to the feature extractor to get some of the features. Other features are grabbed in the splitfile function. TED Metadata files are made here as well.

FeatureCollection.py: A class that holds the featuers extracted. Has some ToString functions.

FeatureExtractor.py: This contains functions that take in feature collections and what features to extract, and then returns a dictionary of features taken from the collection or made from parts of the collection. It also has some functions for extracting features from chunks.

TedMeta.py: Functions for creating the metadata files and writing them to a file, as well as a structure that holds whats in them.

Word2VecHelper.py: A wrapper for Word2Vec functions. It also creates the word2vec model here.

loadingbar.py: The most important feature of Laff-O-Tron is the loading bar. Unfortunately it was turned off because of the multiprocessing but it will return someday! (One of the proudest moments of this thesis was creating the loading bar animation)

summarizeMetaData.py: Reads through the metadata created and summarizes them.

testStuff.py: A file just for playing with functions and testing them out

text2int.py: An experimental function that goes through a string and replaces instances of a written out number with a number (Example: "five" to 5). The issue is just that it doesn't know the difference between "one" the number and "one" the entity ("one would assume...").

-------------------------------------------Web-Scraper-------------------------------------
This web scrapper was made when I was just learning how to use python. I apologize in advance.

TedParser.py: A file for parsing a TED Talk website. It is part of the Web Scraper. Read the comments for how to use this.
Search pages folder: 
    There is pageGrabber.sh in here and it grabs ted talk pages based off of what you put in it. These are search pages. These search pages are used by TedTalkGrabber.sh

    TedTalkGrabberscripts take the pages in search_pages and grabs all the talk websites mentioned in them, then downloads the talk sites, and saves them. These talk sites are then parsed by TedParser.py and the parsed files are stored in parsed_websites.

For copyright reasons, I can't put the parsed websites on github. So you will have to download them yourself. You probably want to make your own scrapper though.
-------------------------------------------Text-Files-------------------------------------
Ted_Laughs.txt: Some of the metadata on the laughs in the talks

Ted_Meta.txt: Some metadata about all the talks parsed

Ted_Meta_testing.txt: Some metadata about the talks that are being used by teststuff.py

negatives.txt: negative data generated by teststuff

output.txt: The output of running main.py is added to the bottom of this file.

positives.txt: postive data generated by teststuff

------------------------------------------Data---------------------------------------------
Past data contains results from previous runs that I have saved.

Pickled data contains saved things. It also has a readme explaining the naming scheme.

==========================================Using Main=======================================
This uses multiprocessing to run multiple instances of Laff-O-Tron at once. This makes testing faster. It should be noted that running multiple instances may slow down your computer, and kill its RAM if too many instances are made at once.

NUM_ITERATIONS = The number of times the coprocesses are run
NUM_COPROCESSES = the number of processes ran at once

Total number of times it is run is NUM_ITERATIONS * NUM_COPROCESSES

To change which features are being looked at, set the input in the dictionary to true. To select which classifiers to test, set those inputs in the array to true. The order is written in comments.